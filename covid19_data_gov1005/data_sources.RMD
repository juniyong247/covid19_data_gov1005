---
title: "Data Sources for Covid-19 Project"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(dplyr)
library(readr)
library(rvest)
library(janitor)
library(skimr)
# library(sf)
# library(maps)
# library(tibble)
library(countrycode)
library(rworldmap)
library(gganimate)
library(chron)
library(date)
library(stringr)
library(readxl)
library(date)
library(chron)

options(scipen = 999)
```

```{r Spread, echo=FALSE}

# Import NYTimes Data

us_states <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))
us_counties <- read.csv(url("https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv"))

saveRDS(us_states, file = "../team_data/nytimes_states.RDS")
saveRDS(us_counties, file = "../team_data/nytimes_counties.RDS")


# Import & Clean Johns Hopkins Data

us_confirmed <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "confirmed") %>%
  select(combined_key, date, confirmed)

us_deaths <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "deaths") %>%
  select(combined_key, date, deaths)

global_confirmed <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "confirmed") %>%
  select(country_region, date, confirmed)

global_deaths <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "deaths") %>%
  select(country_region, date, deaths)

global_recovered <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = c(x1_22_20:x4_15_20), names_to = "date", values_to = "recovered") %>%
  select(country_region, date, recovered)

# global_recovered_2 <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv")) %>%
#   clean_names() %>%
#   pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date",
#                values_to = "confirmed")

us_daily_reports <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_daily_reports_us/04-17-2020.csv")) %>% clean_names()


# Webscrape Worldometer Data

# Webscrape Worldometer Data

worldometer_url <- paste0("https://www.worldometers.info/coronavirus/")
h <- read_html(worldometer_url)
table <- h %>% html_nodes("table")
worldometer <- table[[1]] %>% html_table


world <- worldometer %>% 
  clean_names() %>%
  mutate_at(c("total_cases", "total_deaths", "total_recovered", "total_tests", "tests_1m_pop"), parse_number) %>%
  filter(! country_other %in% c("World", "Total:", "Europe", "North America", "Asia", "South America", 
                                "Africa", "Oceania", "")) %>%
  mutate(incidence = case_when(
    total_cases > 100000 ~ "100,000+ Cases",
    total_cases >= 10000 ~ "10,000+ Cases",
    total_cases >= 1000 ~ "1,000+ Cases",
    TRUE ~ "Less than 1000+ Cases"
  ),
  population_estimate = (total_tests * 1000000) / tests_1m_pop,
         per_capita_cases = total_cases / population_estimate,
         per_capita_tests = total_tests / population_estimate) %>%
  select("country_other", "population_estimate", "total_cases", "total_deaths", "total_recovered", "total_tests", "tests_1m_pop", incidence) %>%
  arrange(desc(total_cases))

saveRDS(world, file = "worldometer.RDS")
```

```{r Spread with Increments, echo=FALSE}

# Updating the date and creating an increment column for the confirmed cases in
# the US.

confirmedCovidUS <- us_confirmed %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(combined_key, new_date, confirmed)

confirmedCovidUS <- confirmedCovidUS %>%
  mutate(helper = c(confirmedCovidUS$confirmed[1], confirmedCovidUS$confirmed[1:(nrow(confirmedCovidUS)-1)])) %>%
  mutate(increment = confirmed - helper) %>%
  group_by(combined_key)

# Updating the date and creating an increment column for the confirmed cases in
# the US.

deathsCovidUS <- us_deaths %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(combined_key, new_date, deaths)

deathsCovidUS <- deathsCovidUS %>%
  mutate(helper = c(deathsCovidUS$deaths[1], deathsCovidUS$deaths[1:(nrow(deathsCovidUS)-1)])) %>%
  mutate(increment = deaths - helper) %>%
  group_by(combined_key)

# Updating the date and creating an increment column for the confirmed cases
# across the globe

confirmedCovidGlobal <- global_confirmed %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(country_region, new_date, confirmed)

confirmedCovidGlobal <- confirmedCovidGlobal %>%
  mutate(helper = c(confirmedCovidGlobal$confirmed[1],
                    confirmedCovidGlobal$confirmed[1:(nrow(confirmedCovidGlobal)-1)])) %>%
  mutate(increment = confirmed - helper) %>%
  group_by(country_region)

# Updating the date and creating an increment column for the deaths  across the
# globe

deathsCovidGlobal <- global_deaths %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(country_region, new_date, deaths)

deathsCovidGlobal <- deathsCovidGlobal %>%
  mutate(helper = c(deathsCovidGlobal$deaths[1],
                    deathsCovidGlobal$deaths[1:(nrow(deathsCovidGlobal)-1)])) %>%
  mutate(increment = deaths - helper) %>%
  group_by(country_region)

# Updating the date and creating an increment column for the recovered cases
# across the globe

recoveredCovidGlobal <- global_recovered %>%
  mutate(sep_date = sub(".", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  select(country_region, new_date, recovered)

recoveredCovidGlobal <- recoveredCovidGlobal %>%
  mutate(helper = c(recoveredCovidGlobal$recovered[1],
                    recoveredCovidGlobal$recovered[1:(nrow(recoveredCovidGlobal)-1)])) %>%
  mutate(increment = recovered - helper) %>%
  group_by(country_region)

# Joined Data US & Global

covidUS <- confirmedCovidUS %>%
  inner_join(deathsCovidUS, by = c("combined_key", "new_date"), suffix = c("_confirmed", "_deaths")) %>%
  select(combined_key, new_date, confirmed, increment_confirmed, deaths, increment_deaths)

covidGlobal <- confirmedCovidGlobal %>%
  inner_join(deathsCovidGlobal, by = c("country_region", "new_date"), suffix = c("_confirmed", "_deaths")) %>%
  inner_join(recoveredCovidGlobal, by = c("country_region", "new_date"), suffix = c("_confirmed", "_recovered")) %>%
  select(country_region, new_date, confirmed, increment_confirmed, deaths, increment_deaths, recovered, increment)

# Johns Hopkins US Daily Report. Used to gather testing rates by State.

testing_by_state <- us_daily_reports %>%
  filter(!is.na(people_tested))

# Saving files

saveRDS(covidUS, file = "covidUS.RDS")
saveRDS(covidGlobal, file = "covidGlobal.RDS")
saveRDS(testing_by_state, file = "tests_per_state.RDS")
```

```{r Policy, echo=FALSE}

# Import Oxford Covid-19 Data

oxford <- read.csv(url("https://raw.githubusercontent.com/OxCGRT/covid-policy-tracker/master/data/OxCGRT_latest.csv")) %>% 
  mutate(new_date = as.Date(as.character(Date), format = "%Y%m%d"))


# Import & Clean JHU CSSE Data (unlike Spread, no increments here), starting
# with Confirmed

global_confirmed <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv")) %>% 
  clean_names() %>% 
  pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date", values_to = "confirmed") %>%
  select(country_region, date, confirmed)

global_confirmed <- global_confirmed %>% 
  mutate(sep_date = sub("x", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  group_by(country_region, new_date) %>%
  summarize(confirmed = sum(confirmed)) 

# JHU Deaths

global_deaths <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date", values_to = "deaths") %>%
  select(country_region, date, deaths) 

global_deaths <- global_deaths %>% 
  mutate(sep_date = sub("x", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  group_by(country_region, new_date) %>%
  summarize(deaths = sum(deaths)) 

# JHU Recovered

global_recovered <- read.csv(url("https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv")) %>% 
  clean_names() %>%
  pivot_longer(cols = -c(province_state, country_region, lat, long), names_to = "date", values_to = "recovered") %>%
  select(country_region, date, recovered)

global_recovered <- global_recovered %>% 
  mutate(sep_date = sub("x", "", date)) %>%
  mutate(new_date = as.Date(sep_date, format = "%m_%d_%y")) %>%
  group_by(country_region, new_date) %>%
  summarize(recovered = sum(recovered))

# Join JHU data 

covidGlobal <- global_confirmed %>%
  inner_join(
    global_deaths, 
    by = c("country_region", "new_date"), 
    suffix = c("_confirmed", "_deaths")
  ) %>%
  inner_join(
    global_recovered, 
    by = c("country_region", "new_date"), 
    suffix = c("_confirmed", "_recovered")
  ) %>%
  select(
    country_region, 
    new_date, 
    confirmed, 
    deaths, 
    recovered
  ) %>% 
  rename(
    Country = country_region
  )

# Use countrycode package to standardize all country names, for easy joining
# with Oxford data (which comes with CountryCode column). Filtering out 2 cruise
# ships, which are not of interest in our analysis.

covidGlobal <- covidGlobal %>% 
  mutate(CountryCode = countrycode(Country, origin = 'country.name', destination = 'iso3c')) %>% 
  filter(Country != "Diamond Princess", Country != "MS Zaandam")


# Join Oxford and JHU Data

stringency <- oxford %>% 
  full_join(covidGlobal, by = c("CountryCode", "new_date")) %>% 
  filter(!is.na(confirmed)) %>% 
  select(
    Country, 
    CountryCode, 
    new_date, 
    C1_School.closing,
    C2_Workplace.closing,
    C3_Cancel.public.events,
    C4_Restrictions.on.gatherings,
    C5_Close.public.transport,
    C6_Stay.at.home.requirements,
    C7_Restrictions.on.internal.movement,
    C8_International.travel.controls,
    E1_Income.support,
    E2_Debt.contract.relief,
    E3_Fiscal.measures,
    E4_International.support,
    H1_Public.information.campaigns,
    H2_Testing.policy,
    H3_Contact.tracing,
    H4_Emergency.investment.in.healthcare,
    H5_Investment.in.vaccines,
    StringencyIndexForDisplay,
    confirmed,
    deaths,
    recovered
    )

# Importing Region and Subregion Lists

regions <- read.csv(url("https://raw.githubusercontent.com/lukes/ISO-3166-Countries-with-Regional-Codes/master/all/all.csv")) %>% 
  select(name, region, sub.region) %>% 
  rename(Country = name)

# Joining with existing dataset

stringency_regions <- stringency %>% 
  full_join(regions, by = "Country")
```

```{r Static Data, echo=FALSE}

# Import population and GDP data from World Bank, latest available 2018

population_data_18 <- read_csv("../gdp/API_pop.csv", skip = 3) %>% 
  clean_names() %>% 
 select(country_code, x2018) %>% 
  rename(pop_2018 = x2018)

gdp_data_18 <- read_csv("../gdp/API_gdp.csv", skip = 3) %>%
  clean_names() %>% 
  select(country_code, x2018) %>% 
  rename(gdp_2018 = x2018)

# Combine to create variable for GDP per capita

gdp_pop_2018 <- gdp_data_18 %>% 
  left_join(population_data_18, by = "country_code") %>% 
  mutate(gdp_per_capita = round(gdp_2018 / pop_2018, digits = 2))


# Create final dataset for POLICY, adding per capita and per case variables and
# log transformation (log base 10)

policy <- stringency_regions %>% 
  full_join(population_data_18, by = c("CountryCode" = "country_code")) %>% 
  mutate(confirmed_per_capita = confirmed / pop_2018,
         deaths_per_confirmed = deaths / confirmed,
         recovered_per_confirmed = recovered / confirmed) %>% 
  mutate(log_confirmed = log10(confirmed), 
         log_deaths = log10(deaths),
         log_recovered = log10(recovered))

# Join policy dataset (for case counts) and gdp_per_capita dataset (from
# previous code chunk, Static Data)

global_gdp_cases <- gdp_pop_2018 %>%
  rename(CountryCode = country_code) %>% 
  full_join(policy, by = "CountryCode") %>%
  select(Country, CountryCode, new_date, sub.region, pop_2018.x, gdp_2018, gdp_per_capita, log_confirmed, log_deaths, log_recovered)

# Saving file

saveRDS(global_gdp_cases, file = "gdp.RDS")
saveRDS(policy, file = "policy.RDS")
```

```{r Economic Impact, echo=FALSE}

# Function to take stock indices from yahoo and scrape data every time its run
# (updated daily)

stock <- function(url) {
  stock_source <- paste0(url)
  stock_html <- read_html(stock_source)
  stock_data <- stock_html %>% 
    html_nodes("table")
  stock_data <- stock_data[[1]] %>% 
    html_table
  stock_data <- stock_data %>% 
    clean_names() %>% 
    select(date, close)
}

# Korea

kospi <- stock("https://finance.yahoo.com/quote/%5EKS11/history?p=%5EKS11") %>% 
  rename(KOSPI = close)
kospi$date <- as.Date(kospi$date, format = "%B %d,%Y") 

# USA

nasdaq <- stock("https://finance.yahoo.com/quote/%5EIXIC/history?p=%5EIXIC") %>% 
  rename(NASDAQ = close)
nasdaq$date <- as.Date(nasdaq$date, format = "%B %d,%Y") 

# World

msci <- stock("https://finance.yahoo.com/quote/MSCI/history?p=MSCI") %>% 
  rename(MSCI = close)
msci$date <- as.Date(msci$date, format = "%B %d,%Y") 

# China

sse_china <- stock("https://finance.yahoo.com/quote/000001.SS/history?p=000001.SS") %>% 
  rename(SSE_China = close)
sse_china$date <- as.Date(sse_china$date, format = "%B %d,%Y") 

# Europe as a whole

dax <- stock("https://finance.yahoo.com/quote/%5EGDAXI/history?p=%5EGDAXI") %>% 
  rename(DAX = close)
dax$date <- as.Date(dax$date, format = "%B %d,%Y") 

# Italy

ftse_italy <- stock("https://finance.yahoo.com/quote/%5EFTSE%3FP%3DFTSE/history/") %>% 
  rename(FTSE_Italy = close)
ftse_italy$date <- as.Date(ftse_italy$date, format = "%B %d,%Y") 

# Spain

ibex_spain <- stock("https://finance.yahoo.com/quote/%5EIBEX/history?p=%5EIBEX") %>% 
  rename(IBEX_Spain = close)
ibex_spain$date <- as.Date(ibex_spain$date, format = "%B %d,%Y") 

# Willing to add more countries here. Perhaps France/Germany? Iran? Singapore? 

stock_data <- kospi %>% 
  left_join(nasdaq, by = "date", na.rm = TRUE) %>% 
  left_join(msci, by = "date", na.rm = TRUE) %>% 
  left_join(sse_china, by = "date", na.rm = TRUE) %>% 
  left_join(dax, by = "date", na.rm = TRUE) %>% 
  left_join(ftse_italy, by = "date", na.rm = TRUE) %>% 
  left_join(ibex_spain, by = "date", na.rm = TRUE) 
stock_data$KOSPI <- gsub(',', '', stock_data$KOSPI) %>% as.numeric(stock_data$KOSPI)
stock_data$NASDAQ <- gsub(',', '', stock_data$NASDAQ) %>% as.numeric(stock_data$NASDAQ)
stock_data$MSCI <- gsub(',', '', stock_data$MSCI) %>% as.numeric(stock_data$MSCI)
stock_data$SSE_China <- gsub(',', '', stock_data$SSE_China) %>% as.numeric(stock_data$SSE_China)
stock_data$DAX <- gsub(',', '', stock_data$DAX) %>% as.numeric(stock_data$DAX)
stock_data$FTSE_Italy <- gsub(',', '', stock_data$FTSE_Italy) %>% as.numeric(stock_data$FTSE_Italy)
stock_data$IBEX_Spain <- gsub(',', '', stock_data$IBEX_Spain) %>% as.numeric(stock_data$IBEX_Spain)

# Tidy stock data and add country indicator

stock_data_tidy <- stock_data %>% 
  pivot_longer(cols = -date, names_to = "stock", values_to = "price") %>% 
  mutate(CountryCode = ifelse(stock == "KOSPI", "KOR", 
                          ifelse(stock == "NASDAQ", "USA", 
                                 ifelse(stock == "MSCI", "World", 
                                        ifelse(stock == "SSE_China", "CHN",
                                               ifelse(stock == "DAX", "DEU",
                                                      ifelse(stock == "FTSE_Italy", "ITA", "ESP"))))))) %>% 
  filter(date >= 2020-01-22)
         

# Join global_gdp_cases to stock data for COMPLETE covid + economic dataset,
# filtering out all observations prior to Jan 22

stock_cases <- policy %>% 
  full_join(stock_data_tidy, by = c("new_date" = "date", "CountryCode")) %>%
  select(Country, CountryCode, new_date, sub.region, log_confirmed, log_deaths, log_recovered, stock, price) %>% 
  filter(!is.na(Country))
     
# Saving file 

saveRDS(stock_cases, file = "stock_cases.RDS")
```

```{r}

    stringency_model <- policy %>%
          select(Country, new_date, recovered, region, StringencyIndexForDisplay) %>%
          filter(!is.na(StringencyIndexForDisplay), new_date == "2020-05-01") %>%
          rep_sample_n(size = nrow(policy), replace = TRUE, reps = 3) %>%
          group_by(replicate, region) %>%
          nest() %>%
          mutate(mod = map(data, ~ lm(StringencyIndexForDisplay ~ recovered, data = .)),
                 reg_results = map(mod, ~ tidy(., conf.int = TRUE)),
                 disp_coef = map_dbl(reg_results, ~ filter(., term == "recovered") %>% pull(estimate)))
        # lower_bound = map_dbl(reg_results, ~ filter(., term == "total_tests") %>% pull(conf.low)),
        # upper_bound = map_dbl(reg_results, ~ filter(., term == "total_tests") %>% pull(conf.high)))
        
        Americas <- stringency_model %>%
          select(replicate, region, disp_coef) %>%
          filter(region == "Americas") %>%
          pull(disp_coef) %>%
          quantile(c(0.025, 0.5, 0.975))
        
        Africa <- stringency_model %>%
          select(replicate, region, disp_coef) %>%
          filter(region == "Africa") %>%
          pull(disp_coef) %>%
          quantile(c(0.025, 0.5, 0.975))
        
        Europe <- stringency_model %>%
          select(replicate, region, disp_coef) %>%
          filter(region == "Europe") %>%
          pull(disp_coef) %>%
          quantile(c(0.025, 0.5, 0.975))
        
        Asia <- stringency_model %>%
          select(replicate, region, disp_coef) %>%
          filter(region == "Asia") %>%
          pull(disp_coef) %>%
          quantile(c(0.025, 0.5, 0.975))
        
        Oceania <- stringency_model %>%
          select(replicate, region, disp_coef) %>%
          filter(region == "Oceania") %>%
          pull(disp_coef) %>%
          quantile(c(0.025, 0.5, 0.975))
        
        Other <- stringency_model %>% 
          select(replicate, region, disp_coef) %>%
          filter(is.na(region)) %>%
          pull(disp_coef) %>%
          quantile(c(0.025, 0.5, 0.975))
        
        updated_policy_tibble <- tibble(index = "Americas", conf_low = Americas[1], point_estimate = Americas[2], conf_high = Americas[3]) %>%
          add_row(index = "Africa", conf_low = Africa[1], point_estimate = Africa[2], conf_high = Africa[3]) %>%
          add_row(index = "Europe", conf_low = Europe[1], point_estimate = Europe[2], conf_high = Europe[3]) %>%
          add_row(index = "Asia", conf_low = Asia[1], point_estimate = Asia[2], conf_high = Asia[3]) %>% 
          add_row(index = "Oceania", conf_low = Oceania[1], point_estimate = Oceania[2], conf_high = Oceania[3]) %>% 
          add_row(index = "Other, including US and UK", conf_low = Other[1], point_estimate = Other[2], conf_high = Other[3])


```

